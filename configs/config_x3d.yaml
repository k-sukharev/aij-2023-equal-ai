seed_everything:
  _target_: lightning.seed_everything
  seed: &seed 42
  workers: True
datamodule:
  _target_: aij_2023_equal_ai.datasets.KineticsDataModule
  data_path: ../input/
  video_path_prefix: ../input/slovo_event_offset_60
  train_transforms:
    _target_: aij_2023_equal_ai.transforms.create_video_transform
    mode: train
    video_key: video
    remove_key: null
    num_samples: 16
    convert_to_float: False
    video_mean: [114.75, 114.75, 114.75]
    video_std: [57.375, 57.375, 57.375]
    min_size: 224
    max_size: 256
    crop_size: 224
    horizontal_flip_prob: 0.5
    aug_type: randaug  # default randaug augmix
    aug_paras: null
  val_transforms:
    _target_: aij_2023_equal_ai.transforms.create_video_transform
    mode: val
    video_key: video
    remove_key: null
    num_samples: 16
    convert_to_float: False
    video_mean: [114.75, 114.75, 114.75]
    video_std: [57.375, 57.375, 57.375]
    min_size: 224
    max_size: 256
    crop_size: 224
    horizontal_flip_prob: 0.5
    aug_type: randaug
    aug_paras: null
  clip_duration: 2.67  # ~80 frames at 30 fps (30 * 2.67)
  seed: *seed
  batch_size: 12
  num_workers: 8
  pin_memory: False
model:
  _target_: aij_2023_equal_ai.models.VideoClassificationLightningModule
  _recursive_: False
  _convert_: partial
  net:
    _target_: pytorchvideo.models.x3d.create_x3d
    # Input clip configs.
    input_channel: 3
    input_clip_length: 16
    input_crop_size: 224
    # Model configs.
    model_num_class: &num_classes 1001
    dropout_rate: 0.5
    width_factor: 2.0
    depth_factor: 2.2
    # Normalization configs.
    norm:
      _target_: torch.nn.BatchNorm3d
      _partial_: True
    norm_eps: 1.e-5
    norm_momentum: 0.1
    # Activation configs.
    activation:
      _target_: torch.nn.ReLU
      _partial_: True
    # Stem configs.
    stem_dim_in: 12
    stem_conv_kernel_size: [5, 3, 3]
    stem_conv_stride: [1, 2, 2]
    # Stage configs.
    stage_conv_kernel_size: [
        [3, 3, 3],
        [3, 3, 3],
        [3, 3, 3],
        [3, 3, 3]
    ]
    stage_spatial_stride: [2, 2, 2, 2]
    stage_temporal_stride: [1, 1, 1, 1]
    bottleneck:
      _target_: pytorchvideo.models.x3d.create_x3d_bottleneck_block
      _partial_: True
    bottleneck_factor: 2.25
    se_ratio: 0.0625
    inner_act:
      _target_: pytorchvideo.layers.swish.Swish
      _partial_: True
    # Head configs.
    head_dim_out: 2048
    head_pool_act:
      _target_: torch.nn.ReLU
      _partial_: True
    head_bn_lin5_on: False
    head_activation: null
    head_output_with_global_average: True
  num_classes: *num_classes
  batch_key: video
  optimizer:
    _target_: torch.optim.AdamW
    _convert_: partial
    lr: 1.e-3
    weight_decay: 1.e-2
  scheduler_dict:
    interval: step
  scheduler:
    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR
    warmup_epochs: 10
    max_epochs: &max_epochs 300
    warmup_start_lr: 0.0
    eta_min: 0.0
trainer:
  _target_: lightning.pytorch.Trainer
  accelerator: gpu
  # accumulate_grad_batches: 5
  callbacks:
    - _target_: lightning.pytorch.callbacks.LearningRateMonitor
    - _target_: lightning.pytorch.callbacks.ModelCheckpoint
      monitor: val_acc
      verbose: True
      save_last: True
      mode: max
    # - _target_: aij_2023_equal_ai.callbacks.EpochStopping
    #   epoch_threshold: 140
  # deterministic: warn
  devices: 2
  max_epochs: *max_epochs
  # profiler: simple
  # fast_dev_run: True
  # use_distributed_sampler: False
  # precision: 16-mixed
  # strategy: ddp_find_unused_parameters_true
  # sync_batchnorm: True
# ckpt_path: null
ckpt_path: lightning_logs/version_0/checkpoints/last.ckpt
